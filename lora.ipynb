{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f396f201-d921-4fe4-95b5-ff7237a0fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.24.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torchaudio\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.13/site-packages (4.5.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /opt/anaconda3/lib/python3.13/site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.13/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.13/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (2.9.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (from peft) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (0.26.0)\n",
      "Requirement already satisfied: safetensors in /opt/anaconda3/lib/python3.13/site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.13.0->peft) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.13/site-packages (from transformers->peft) (0.21.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "zsh:1: no matches found: transformers[torch]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 0.26.0 not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install transformers datasets\n",
    "!pip install peft\n",
    "!pip install evaluate scikit-learn transformers[torch]\n",
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50179772-8165-4a2e-9b51-c86942fa2721",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d1c7119-6624-4604-b4b0-f15c905390d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be48e0ce12724839b1c9fab5a22f3f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"stanfordnlp/imdb\")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = imdb.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6714ed0a-053f-41d5-b340-353a6d2b3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = tokenized_datasets['train'].shuffle(42).select(range(5000))\n",
    "shuffled_set =  tokenized_datasets['test'].shuffle(42)\n",
    "validation_set  = shuffled_set.select(range(1000))\n",
    "test_set = shuffled_set.select(range(1000, 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624c1dc-cbca-4dd0-959f-e482182d94aa",
   "metadata": {},
   "source": [
    "## First method : Using the transformers library and pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25693f50-39a8-4d5f-97bb-c8f1a5ccefff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0176c44",
   "metadata": {},
   "source": [
    "## Fine-tuning the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cf32374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f0272",
   "metadata": {},
   "source": [
    "## LoRA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c12fe280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeddings.word_embeddings.weight',\n",
       " 'embeddings.position_embeddings.weight',\n",
       " 'embeddings.token_type_embeddings.weight',\n",
       " 'embeddings.LayerNorm.weight',\n",
       " 'embeddings.LayerNorm.bias',\n",
       " 'encoder.layer.0.attention.self.query.weight',\n",
       " 'encoder.layer.0.attention.self.query.bias',\n",
       " 'encoder.layer.0.attention.self.key.weight',\n",
       " 'encoder.layer.0.attention.self.key.bias',\n",
       " 'encoder.layer.0.attention.self.value.weight',\n",
       " 'encoder.layer.0.attention.self.value.bias',\n",
       " 'encoder.layer.0.attention.output.dense.weight',\n",
       " 'encoder.layer.0.attention.output.dense.bias',\n",
       " 'encoder.layer.0.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.0.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.0.intermediate.dense.weight',\n",
       " 'encoder.layer.0.intermediate.dense.bias',\n",
       " 'encoder.layer.0.output.dense.weight',\n",
       " 'encoder.layer.0.output.dense.bias',\n",
       " 'encoder.layer.0.output.LayerNorm.weight',\n",
       " 'encoder.layer.0.output.LayerNorm.bias',\n",
       " 'encoder.layer.1.attention.self.query.weight',\n",
       " 'encoder.layer.1.attention.self.query.bias',\n",
       " 'encoder.layer.1.attention.self.key.weight',\n",
       " 'encoder.layer.1.attention.self.key.bias',\n",
       " 'encoder.layer.1.attention.self.value.weight',\n",
       " 'encoder.layer.1.attention.self.value.bias',\n",
       " 'encoder.layer.1.attention.output.dense.weight',\n",
       " 'encoder.layer.1.attention.output.dense.bias',\n",
       " 'encoder.layer.1.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.1.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.1.intermediate.dense.weight',\n",
       " 'encoder.layer.1.intermediate.dense.bias',\n",
       " 'encoder.layer.1.output.dense.weight',\n",
       " 'encoder.layer.1.output.dense.bias',\n",
       " 'encoder.layer.1.output.LayerNorm.weight',\n",
       " 'encoder.layer.1.output.LayerNorm.bias',\n",
       " 'encoder.layer.2.attention.self.query.weight',\n",
       " 'encoder.layer.2.attention.self.query.bias',\n",
       " 'encoder.layer.2.attention.self.key.weight',\n",
       " 'encoder.layer.2.attention.self.key.bias',\n",
       " 'encoder.layer.2.attention.self.value.weight',\n",
       " 'encoder.layer.2.attention.self.value.bias',\n",
       " 'encoder.layer.2.attention.output.dense.weight',\n",
       " 'encoder.layer.2.attention.output.dense.bias',\n",
       " 'encoder.layer.2.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.2.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.2.intermediate.dense.weight',\n",
       " 'encoder.layer.2.intermediate.dense.bias',\n",
       " 'encoder.layer.2.output.dense.weight',\n",
       " 'encoder.layer.2.output.dense.bias',\n",
       " 'encoder.layer.2.output.LayerNorm.weight',\n",
       " 'encoder.layer.2.output.LayerNorm.bias',\n",
       " 'encoder.layer.3.attention.self.query.weight',\n",
       " 'encoder.layer.3.attention.self.query.bias',\n",
       " 'encoder.layer.3.attention.self.key.weight',\n",
       " 'encoder.layer.3.attention.self.key.bias',\n",
       " 'encoder.layer.3.attention.self.value.weight',\n",
       " 'encoder.layer.3.attention.self.value.bias',\n",
       " 'encoder.layer.3.attention.output.dense.weight',\n",
       " 'encoder.layer.3.attention.output.dense.bias',\n",
       " 'encoder.layer.3.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.3.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.3.intermediate.dense.weight',\n",
       " 'encoder.layer.3.intermediate.dense.bias',\n",
       " 'encoder.layer.3.output.dense.weight',\n",
       " 'encoder.layer.3.output.dense.bias',\n",
       " 'encoder.layer.3.output.LayerNorm.weight',\n",
       " 'encoder.layer.3.output.LayerNorm.bias',\n",
       " 'encoder.layer.4.attention.self.query.weight',\n",
       " 'encoder.layer.4.attention.self.query.bias',\n",
       " 'encoder.layer.4.attention.self.key.weight',\n",
       " 'encoder.layer.4.attention.self.key.bias',\n",
       " 'encoder.layer.4.attention.self.value.weight',\n",
       " 'encoder.layer.4.attention.self.value.bias',\n",
       " 'encoder.layer.4.attention.output.dense.weight',\n",
       " 'encoder.layer.4.attention.output.dense.bias',\n",
       " 'encoder.layer.4.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.4.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.4.intermediate.dense.weight',\n",
       " 'encoder.layer.4.intermediate.dense.bias',\n",
       " 'encoder.layer.4.output.dense.weight',\n",
       " 'encoder.layer.4.output.dense.bias',\n",
       " 'encoder.layer.4.output.LayerNorm.weight',\n",
       " 'encoder.layer.4.output.LayerNorm.bias',\n",
       " 'encoder.layer.5.attention.self.query.weight',\n",
       " 'encoder.layer.5.attention.self.query.bias',\n",
       " 'encoder.layer.5.attention.self.key.weight',\n",
       " 'encoder.layer.5.attention.self.key.bias',\n",
       " 'encoder.layer.5.attention.self.value.weight',\n",
       " 'encoder.layer.5.attention.self.value.bias',\n",
       " 'encoder.layer.5.attention.output.dense.weight',\n",
       " 'encoder.layer.5.attention.output.dense.bias',\n",
       " 'encoder.layer.5.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.5.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.5.intermediate.dense.weight',\n",
       " 'encoder.layer.5.intermediate.dense.bias',\n",
       " 'encoder.layer.5.output.dense.weight',\n",
       " 'encoder.layer.5.output.dense.bias',\n",
       " 'encoder.layer.5.output.LayerNorm.weight',\n",
       " 'encoder.layer.5.output.LayerNorm.bias',\n",
       " 'encoder.layer.6.attention.self.query.weight',\n",
       " 'encoder.layer.6.attention.self.query.bias',\n",
       " 'encoder.layer.6.attention.self.key.weight',\n",
       " 'encoder.layer.6.attention.self.key.bias',\n",
       " 'encoder.layer.6.attention.self.value.weight',\n",
       " 'encoder.layer.6.attention.self.value.bias',\n",
       " 'encoder.layer.6.attention.output.dense.weight',\n",
       " 'encoder.layer.6.attention.output.dense.bias',\n",
       " 'encoder.layer.6.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.6.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.6.intermediate.dense.weight',\n",
       " 'encoder.layer.6.intermediate.dense.bias',\n",
       " 'encoder.layer.6.output.dense.weight',\n",
       " 'encoder.layer.6.output.dense.bias',\n",
       " 'encoder.layer.6.output.LayerNorm.weight',\n",
       " 'encoder.layer.6.output.LayerNorm.bias',\n",
       " 'encoder.layer.7.attention.self.query.weight',\n",
       " 'encoder.layer.7.attention.self.query.bias',\n",
       " 'encoder.layer.7.attention.self.key.weight',\n",
       " 'encoder.layer.7.attention.self.key.bias',\n",
       " 'encoder.layer.7.attention.self.value.weight',\n",
       " 'encoder.layer.7.attention.self.value.bias',\n",
       " 'encoder.layer.7.attention.output.dense.weight',\n",
       " 'encoder.layer.7.attention.output.dense.bias',\n",
       " 'encoder.layer.7.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.7.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.7.intermediate.dense.weight',\n",
       " 'encoder.layer.7.intermediate.dense.bias',\n",
       " 'encoder.layer.7.output.dense.weight',\n",
       " 'encoder.layer.7.output.dense.bias',\n",
       " 'encoder.layer.7.output.LayerNorm.weight',\n",
       " 'encoder.layer.7.output.LayerNorm.bias',\n",
       " 'encoder.layer.8.attention.self.query.weight',\n",
       " 'encoder.layer.8.attention.self.query.bias',\n",
       " 'encoder.layer.8.attention.self.key.weight',\n",
       " 'encoder.layer.8.attention.self.key.bias',\n",
       " 'encoder.layer.8.attention.self.value.weight',\n",
       " 'encoder.layer.8.attention.self.value.bias',\n",
       " 'encoder.layer.8.attention.output.dense.weight',\n",
       " 'encoder.layer.8.attention.output.dense.bias',\n",
       " 'encoder.layer.8.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.8.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.8.intermediate.dense.weight',\n",
       " 'encoder.layer.8.intermediate.dense.bias',\n",
       " 'encoder.layer.8.output.dense.weight',\n",
       " 'encoder.layer.8.output.dense.bias',\n",
       " 'encoder.layer.8.output.LayerNorm.weight',\n",
       " 'encoder.layer.8.output.LayerNorm.bias',\n",
       " 'encoder.layer.9.attention.self.query.weight',\n",
       " 'encoder.layer.9.attention.self.query.bias',\n",
       " 'encoder.layer.9.attention.self.key.weight',\n",
       " 'encoder.layer.9.attention.self.key.bias',\n",
       " 'encoder.layer.9.attention.self.value.weight',\n",
       " 'encoder.layer.9.attention.self.value.bias',\n",
       " 'encoder.layer.9.attention.output.dense.weight',\n",
       " 'encoder.layer.9.attention.output.dense.bias',\n",
       " 'encoder.layer.9.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.9.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.9.intermediate.dense.weight',\n",
       " 'encoder.layer.9.intermediate.dense.bias',\n",
       " 'encoder.layer.9.output.dense.weight',\n",
       " 'encoder.layer.9.output.dense.bias',\n",
       " 'encoder.layer.9.output.LayerNorm.weight',\n",
       " 'encoder.layer.9.output.LayerNorm.bias',\n",
       " 'encoder.layer.10.attention.self.query.weight',\n",
       " 'encoder.layer.10.attention.self.query.bias',\n",
       " 'encoder.layer.10.attention.self.key.weight',\n",
       " 'encoder.layer.10.attention.self.key.bias',\n",
       " 'encoder.layer.10.attention.self.value.weight',\n",
       " 'encoder.layer.10.attention.self.value.bias',\n",
       " 'encoder.layer.10.attention.output.dense.weight',\n",
       " 'encoder.layer.10.attention.output.dense.bias',\n",
       " 'encoder.layer.10.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.10.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.10.intermediate.dense.weight',\n",
       " 'encoder.layer.10.intermediate.dense.bias',\n",
       " 'encoder.layer.10.output.dense.weight',\n",
       " 'encoder.layer.10.output.dense.bias',\n",
       " 'encoder.layer.10.output.LayerNorm.weight',\n",
       " 'encoder.layer.10.output.LayerNorm.bias',\n",
       " 'encoder.layer.11.attention.self.query.weight',\n",
       " 'encoder.layer.11.attention.self.query.bias',\n",
       " 'encoder.layer.11.attention.self.key.weight',\n",
       " 'encoder.layer.11.attention.self.key.bias',\n",
       " 'encoder.layer.11.attention.self.value.weight',\n",
       " 'encoder.layer.11.attention.self.value.bias',\n",
       " 'encoder.layer.11.attention.output.dense.weight',\n",
       " 'encoder.layer.11.attention.output.dense.bias',\n",
       " 'encoder.layer.11.attention.output.LayerNorm.weight',\n",
       " 'encoder.layer.11.attention.output.LayerNorm.bias',\n",
       " 'encoder.layer.11.intermediate.dense.weight',\n",
       " 'encoder.layer.11.intermediate.dense.bias',\n",
       " 'encoder.layer.11.output.dense.weight',\n",
       " 'encoder.layer.11.output.dense.bias',\n",
       " 'encoder.layer.11.output.LayerNorm.weight',\n",
       " 'encoder.layer.11.output.LayerNorm.bias',\n",
       " 'pooler.dense.weight',\n",
       " 'pooler.dense.bias']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v  in model.bert.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "759b1ef3-25e9-44aa-82e0-af70ce76abfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the model \n",
      "\n",
      " BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"What is the model \\n\\n {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82be16-830b-474b-b5f6-a98df468391f",
   "metadata": {},
   "source": [
    "### Create the LoRA module\n",
    "\n",
    "We will consider in this module the original linear, and the down and up projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ba190fe-401c-411c-9958-1e74d51bcaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, rank: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim, bias=True)\n",
    "        self.lora_a = nn.Linear(in_dim, rank, bias=False)\n",
    "        self.lora_b = nn.Linear(rank, out_dim, bias=False)\n",
    "\n",
    "        nn.init.zeros_(self.lora_a.weight)\n",
    "        nn.init.zeros_(self.lora_b.weight)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x) + self.lora_b(self.lora_a(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32301774-a17f-44dd-a7b3-e7aa8d15e655",
   "metadata": {},
   "source": [
    "### Create a function replacing linear by lora module\n",
    "From the original Linear module return a LoRA module\n",
    "* The linear of the LoRA linear must be initialised with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cbf7015-fdd5-41ea-b865-5d2021b970d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_lora(linear):\n",
    "    weight = linear.weight.data\n",
    "    bias = linear.bias.data if linear.bias is not None else None\n",
    "\n",
    "    out_dim, in_dim = weight.shape\n",
    "    lora = LoRALinear(in_dim, out_dim, rank=8)\n",
    "\n",
    "    lora.linear.weight.data = weight.clone()\n",
    "    if bias is not None:\n",
    "        lora.linear.bias.data = bias.clone()\n",
    "\n",
    "    return lora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e3fac-0662-4f41-937f-d9736800103c",
   "metadata": {},
   "source": [
    "We now replace the target linear by the LoRALinear described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68d0fb24-cdaa-4cbd-ac75-a00a12c9a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "lora_model = copy.deepcopy(model)\n",
    "lora_parameters = []\n",
    "\n",
    "for block in lora_model.bert.encoder.layer:\n",
    "    block.attention.self.query = linear_to_lora(block.attention.self.query)\n",
    "    block.attention.self.key   = linear_to_lora(block.attention.self.key)\n",
    "    block.attention.self.value = linear_to_lora(block.attention.self.value)\n",
    "\n",
    "    lora_parameters += list(block.attention.self.query.lora_a.parameters())\n",
    "    lora_parameters += list(block.attention.self.query.lora_b.parameters())\n",
    "    lora_parameters += list(block.attention.self.key.lora_a.parameters())\n",
    "    lora_parameters += list(block.attention.self.key.lora_b.parameters())\n",
    "    lora_parameters += list(block.attention.self.value.lora_a.parameters())\n",
    "    lora_parameters += list(block.attention.self.value.lora_b.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8484560f-2d4f-4e77-a381-f3b6dbd581d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the model modified with LoRA: \n",
      "\n",
      " BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): LoRALinear(\n",
      "                (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (lora_a): Linear(in_features=768, out_features=8, bias=False)\n",
      "                (lora_b): Linear(in_features=8, out_features=768, bias=False)\n",
      "              )\n",
      "              (key): LoRALinear(\n",
      "                (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (lora_a): Linear(in_features=768, out_features=8, bias=False)\n",
      "                (lora_b): Linear(in_features=8, out_features=768, bias=False)\n",
      "              )\n",
      "              (value): LoRALinear(\n",
      "                (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (lora_a): Linear(in_features=768, out_features=8, bias=False)\n",
      "                (lora_b): Linear(in_features=8, out_features=768, bias=False)\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"What is the model modified with LoRA: \\n\\n {lora_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad8e4a-2d59-47c9-87dc-3b26836dada0",
   "metadata": {},
   "source": [
    "### Defining module requiring grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00bed4e1-e5ef-4cfe-83a8-dc915bc3070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.linear.weight\n",
      "encoder.layer.0.attention.self.query.linear.bias\n",
      "encoder.layer.0.attention.self.query.lora_a.weight\n",
      "encoder.layer.0.attention.self.query.lora_b.weight\n",
      "encoder.layer.0.attention.self.key.linear.weight\n",
      "encoder.layer.0.attention.self.key.linear.bias\n",
      "encoder.layer.0.attention.self.key.lora_a.weight\n",
      "encoder.layer.0.attention.self.key.lora_b.weight\n",
      "encoder.layer.0.attention.self.value.linear.weight\n",
      "encoder.layer.0.attention.self.value.linear.bias\n",
      "encoder.layer.0.attention.self.value.lora_a.weight\n",
      "encoder.layer.0.attention.self.value.lora_b.weight\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.linear.weight\n",
      "encoder.layer.1.attention.self.query.linear.bias\n",
      "encoder.layer.1.attention.self.query.lora_a.weight\n",
      "encoder.layer.1.attention.self.query.lora_b.weight\n",
      "encoder.layer.1.attention.self.key.linear.weight\n",
      "encoder.layer.1.attention.self.key.linear.bias\n",
      "encoder.layer.1.attention.self.key.lora_a.weight\n",
      "encoder.layer.1.attention.self.key.lora_b.weight\n",
      "encoder.layer.1.attention.self.value.linear.weight\n",
      "encoder.layer.1.attention.self.value.linear.bias\n",
      "encoder.layer.1.attention.self.value.lora_a.weight\n",
      "encoder.layer.1.attention.self.value.lora_b.weight\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.linear.weight\n",
      "encoder.layer.2.attention.self.query.linear.bias\n",
      "encoder.layer.2.attention.self.query.lora_a.weight\n",
      "encoder.layer.2.attention.self.query.lora_b.weight\n",
      "encoder.layer.2.attention.self.key.linear.weight\n",
      "encoder.layer.2.attention.self.key.linear.bias\n",
      "encoder.layer.2.attention.self.key.lora_a.weight\n",
      "encoder.layer.2.attention.self.key.lora_b.weight\n",
      "encoder.layer.2.attention.self.value.linear.weight\n",
      "encoder.layer.2.attention.self.value.linear.bias\n",
      "encoder.layer.2.attention.self.value.lora_a.weight\n",
      "encoder.layer.2.attention.self.value.lora_b.weight\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.linear.weight\n",
      "encoder.layer.3.attention.self.query.linear.bias\n",
      "encoder.layer.3.attention.self.query.lora_a.weight\n",
      "encoder.layer.3.attention.self.query.lora_b.weight\n",
      "encoder.layer.3.attention.self.key.linear.weight\n",
      "encoder.layer.3.attention.self.key.linear.bias\n",
      "encoder.layer.3.attention.self.key.lora_a.weight\n",
      "encoder.layer.3.attention.self.key.lora_b.weight\n",
      "encoder.layer.3.attention.self.value.linear.weight\n",
      "encoder.layer.3.attention.self.value.linear.bias\n",
      "encoder.layer.3.attention.self.value.lora_a.weight\n",
      "encoder.layer.3.attention.self.value.lora_b.weight\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.linear.weight\n",
      "encoder.layer.4.attention.self.query.linear.bias\n",
      "encoder.layer.4.attention.self.query.lora_a.weight\n",
      "encoder.layer.4.attention.self.query.lora_b.weight\n",
      "encoder.layer.4.attention.self.key.linear.weight\n",
      "encoder.layer.4.attention.self.key.linear.bias\n",
      "encoder.layer.4.attention.self.key.lora_a.weight\n",
      "encoder.layer.4.attention.self.key.lora_b.weight\n",
      "encoder.layer.4.attention.self.value.linear.weight\n",
      "encoder.layer.4.attention.self.value.linear.bias\n",
      "encoder.layer.4.attention.self.value.lora_a.weight\n",
      "encoder.layer.4.attention.self.value.lora_b.weight\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.linear.weight\n",
      "encoder.layer.5.attention.self.query.linear.bias\n",
      "encoder.layer.5.attention.self.query.lora_a.weight\n",
      "encoder.layer.5.attention.self.query.lora_b.weight\n",
      "encoder.layer.5.attention.self.key.linear.weight\n",
      "encoder.layer.5.attention.self.key.linear.bias\n",
      "encoder.layer.5.attention.self.key.lora_a.weight\n",
      "encoder.layer.5.attention.self.key.lora_b.weight\n",
      "encoder.layer.5.attention.self.value.linear.weight\n",
      "encoder.layer.5.attention.self.value.linear.bias\n",
      "encoder.layer.5.attention.self.value.lora_a.weight\n",
      "encoder.layer.5.attention.self.value.lora_b.weight\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.linear.weight\n",
      "encoder.layer.6.attention.self.query.linear.bias\n",
      "encoder.layer.6.attention.self.query.lora_a.weight\n",
      "encoder.layer.6.attention.self.query.lora_b.weight\n",
      "encoder.layer.6.attention.self.key.linear.weight\n",
      "encoder.layer.6.attention.self.key.linear.bias\n",
      "encoder.layer.6.attention.self.key.lora_a.weight\n",
      "encoder.layer.6.attention.self.key.lora_b.weight\n",
      "encoder.layer.6.attention.self.value.linear.weight\n",
      "encoder.layer.6.attention.self.value.linear.bias\n",
      "encoder.layer.6.attention.self.value.lora_a.weight\n",
      "encoder.layer.6.attention.self.value.lora_b.weight\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.linear.weight\n",
      "encoder.layer.7.attention.self.query.linear.bias\n",
      "encoder.layer.7.attention.self.query.lora_a.weight\n",
      "encoder.layer.7.attention.self.query.lora_b.weight\n",
      "encoder.layer.7.attention.self.key.linear.weight\n",
      "encoder.layer.7.attention.self.key.linear.bias\n",
      "encoder.layer.7.attention.self.key.lora_a.weight\n",
      "encoder.layer.7.attention.self.key.lora_b.weight\n",
      "encoder.layer.7.attention.self.value.linear.weight\n",
      "encoder.layer.7.attention.self.value.linear.bias\n",
      "encoder.layer.7.attention.self.value.lora_a.weight\n",
      "encoder.layer.7.attention.self.value.lora_b.weight\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.linear.weight\n",
      "encoder.layer.8.attention.self.query.linear.bias\n",
      "encoder.layer.8.attention.self.query.lora_a.weight\n",
      "encoder.layer.8.attention.self.query.lora_b.weight\n",
      "encoder.layer.8.attention.self.key.linear.weight\n",
      "encoder.layer.8.attention.self.key.linear.bias\n",
      "encoder.layer.8.attention.self.key.lora_a.weight\n",
      "encoder.layer.8.attention.self.key.lora_b.weight\n",
      "encoder.layer.8.attention.self.value.linear.weight\n",
      "encoder.layer.8.attention.self.value.linear.bias\n",
      "encoder.layer.8.attention.self.value.lora_a.weight\n",
      "encoder.layer.8.attention.self.value.lora_b.weight\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.linear.weight\n",
      "encoder.layer.9.attention.self.query.linear.bias\n",
      "encoder.layer.9.attention.self.query.lora_a.weight\n",
      "encoder.layer.9.attention.self.query.lora_b.weight\n",
      "encoder.layer.9.attention.self.key.linear.weight\n",
      "encoder.layer.9.attention.self.key.linear.bias\n",
      "encoder.layer.9.attention.self.key.lora_a.weight\n",
      "encoder.layer.9.attention.self.key.lora_b.weight\n",
      "encoder.layer.9.attention.self.value.linear.weight\n",
      "encoder.layer.9.attention.self.value.linear.bias\n",
      "encoder.layer.9.attention.self.value.lora_a.weight\n",
      "encoder.layer.9.attention.self.value.lora_b.weight\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.linear.weight\n",
      "encoder.layer.10.attention.self.query.linear.bias\n",
      "encoder.layer.10.attention.self.query.lora_a.weight\n",
      "encoder.layer.10.attention.self.query.lora_b.weight\n",
      "encoder.layer.10.attention.self.key.linear.weight\n",
      "encoder.layer.10.attention.self.key.linear.bias\n",
      "encoder.layer.10.attention.self.key.lora_a.weight\n",
      "encoder.layer.10.attention.self.key.lora_b.weight\n",
      "encoder.layer.10.attention.self.value.linear.weight\n",
      "encoder.layer.10.attention.self.value.linear.bias\n",
      "encoder.layer.10.attention.self.value.lora_a.weight\n",
      "encoder.layer.10.attention.self.value.lora_b.weight\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.linear.weight\n",
      "encoder.layer.11.attention.self.query.linear.bias\n",
      "encoder.layer.11.attention.self.query.lora_a.weight\n",
      "encoder.layer.11.attention.self.query.lora_b.weight\n",
      "encoder.layer.11.attention.self.key.linear.weight\n",
      "encoder.layer.11.attention.self.key.linear.bias\n",
      "encoder.layer.11.attention.self.key.lora_a.weight\n",
      "encoder.layer.11.attention.self.key.lora_b.weight\n",
      "encoder.layer.11.attention.self.value.linear.weight\n",
      "encoder.layer.11.attention.self.value.linear.bias\n",
      "encoder.layer.11.attention.self.value.lora_a.weight\n",
      "encoder.layer.11.attention.self.value.lora_b.weight\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for k,v  in lora_model.bert.named_parameters():\n",
    "    print(k)\n",
    "    if ('lora' in k):\n",
    "        v.requires_grad = True\n",
    "    else:\n",
    "        v.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f724d4-b1bb-40c2-8902-ab9ea7fe9bd6",
   "metadata": {},
   "source": [
    "## Using transformers Trainer to fine-tune with LoRA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6f2f95c-aff2-46a8-abc0-d21bdd663bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b569898b933446609306a56b6df90b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4637bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate.utils.memory\n",
    "\n",
    "if not hasattr(accelerate.utils.memory, \"clear_device_cache\"):\n",
    "    def clear_device_cache():\n",
    "        pass\n",
    "    accelerate.utils.memory.clear_device_cache = clear_device_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7f4a058-fcfc-448c-b1c5-e945cc7f58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_custom_lora\", \n",
    "                                  eval_strategy=\"steps\",\n",
    "                                  eval_steps= 128,\n",
    "                                  num_train_epochs=2,)\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset= training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8971eec6-b562-45c4-8c7a-8affe54a4364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25d6e732f114f7ca31bc2a48e8a48eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc37b8828f6f4294a2385e6eb671df38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6796972155570984, 'eval_accuracy': 0.596, 'eval_runtime': 29.1831, 'eval_samples_per_second': 34.266, 'eval_steps_per_second': 4.283, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7783a27b3a4394b4553ad4fa67d851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6731536388397217, 'eval_accuracy': 0.618, 'eval_runtime': 28.959, 'eval_samples_per_second': 34.532, 'eval_steps_per_second': 4.316, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda0f70abd1246daaa8c703c17295d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.66897052526474, 'eval_accuracy': 0.638, 'eval_runtime': 28.9397, 'eval_samples_per_second': 34.555, 'eval_steps_per_second': 4.319, 'epoch': 0.61}\n",
      "{'loss': 0.6846, 'grad_norm': 4.1917033195495605, 'learning_rate': 3e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d741d91967634350b38e2e9c31d66b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6640650629997253, 'eval_accuracy': 0.634, 'eval_runtime': 28.6539, 'eval_samples_per_second': 34.899, 'eval_steps_per_second': 4.362, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c05a246679498687ff2bb7bf545bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.67023766040802, 'eval_accuracy': 0.587, 'eval_runtime': 28.6698, 'eval_samples_per_second': 34.88, 'eval_steps_per_second': 4.36, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd71efdae10c464d9020b635855c3807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6599230766296387, 'eval_accuracy': 0.627, 'eval_runtime': 28.7638, 'eval_samples_per_second': 34.766, 'eval_steps_per_second': 4.346, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440b4262046542969b4c56d91a40e0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6599308252334595, 'eval_accuracy': 0.619, 'eval_runtime': 28.7018, 'eval_samples_per_second': 34.841, 'eval_steps_per_second': 4.355, 'epoch': 1.43}\n",
      "{'loss': 0.675, 'grad_norm': 6.463617324829102, 'learning_rate': 1e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abcb7459d974e6997d6617fe1fe8600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6577138900756836, 'eval_accuracy': 0.631, 'eval_runtime': 28.6689, 'eval_samples_per_second': 34.881, 'eval_steps_per_second': 4.36, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3ba47467124803917d79dbd8152042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6574687361717224, 'eval_accuracy': 0.633, 'eval_runtime': 28.7038, 'eval_samples_per_second': 34.839, 'eval_steps_per_second': 4.355, 'epoch': 1.84}\n",
      "{'train_runtime': 1011.0103, 'train_samples_per_second': 9.891, 'train_steps_per_second': 1.236, 'train_loss': 0.6796511352539063, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.6796511352539063, metrics={'train_runtime': 1011.0103, 'train_samples_per_second': 9.891, 'train_steps_per_second': 1.236, 'total_flos': 2644700098560000.0, 'train_loss': 0.6796511352539063, 'epoch': 2.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ea997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6797</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>640</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>768</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>896</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1152</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Step  Training Loss  Validation Loss  Accuracy\n",
       "0   128            NaN           0.6797     0.596\n",
       "1   256            NaN           0.6732     0.618\n",
       "2   384            NaN           0.6690     0.638\n",
       "3   512         0.6846           0.6641     0.634\n",
       "4   640         0.6846           0.6702     0.587\n",
       "5   768         0.6846           0.6599     0.627\n",
       "6   896         0.6846           0.6599     0.619\n",
       "7  1024         0.6750           0.6577     0.631\n",
       "8  1152         0.6750           0.6575     0.633"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "logs = trainer.state.log_history\n",
    "\n",
    "train_losses = [\n",
    "    (log[\"step\"], log[\"loss\"])\n",
    "    for log in logs\n",
    "    if \"loss\" in log and \"eval_loss\" not in log\n",
    "]\n",
    "\n",
    "def get_closest_train_loss(step):\n",
    "    candidates = [loss for s, loss in train_losses if s <= step]\n",
    "    if len(candidates) == 0:\n",
    "        return math.nan\n",
    "    return candidates[-1]\n",
    "\n",
    "rows = []\n",
    "for log in logs:\n",
    "    if \"eval_loss\" in log:\n",
    "        step = log[\"step\"]\n",
    "        rows.append({\n",
    "            \"Step\": step,\n",
    "            \"Training Loss\": round(get_closest_train_loss(step), 4),\n",
    "            \"Validation Loss\": round(log[\"eval_loss\"], 4),\n",
    "            \"Accuracy\": round(log[\"eval_accuracy\"], 4)\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f8f99-26f4-4573-a4d7-7ee87f43f587",
   "metadata": {},
   "source": [
    "## Using PEFT library to fine-tune with LoRA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94a30566-0231-420d-8709-1be4fb238f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType,  get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, r=1, lora_alpha=1, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased', \n",
    "    num_labels=2\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d361529-f3e8-44b3-8fcd-5640679405f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_custom_lora\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=128,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=128,\n",
    "    num_train_epochs=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset= training_set,\n",
    "    eval_dataset=validation_set,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cf108d7-6ec0-4ee8-8c71-15accf8ceb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d0ff0df49b4139aa06ee57fbafbbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7068, 'grad_norm': 3.667567729949951, 'learning_rate': 4.488e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3728ef8de7948edb487d01bff5c6516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6885630488395691, 'eval_accuracy': 0.551, 'eval_runtime': 28.8171, 'eval_samples_per_second': 34.702, 'eval_steps_per_second': 4.338, 'epoch': 0.2}\n",
      "{'loss': 0.6895, 'grad_norm': 3.7987382411956787, 'learning_rate': 3.9760000000000006e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740a40edfb8640518864c183a6f5ff46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6796603798866272, 'eval_accuracy': 0.595, 'eval_runtime': 28.9166, 'eval_samples_per_second': 34.582, 'eval_steps_per_second': 4.323, 'epoch': 0.41}\n",
      "{'loss': 0.6873, 'grad_norm': 5.818635940551758, 'learning_rate': 3.464e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d237b2e0ecc46cc85704fb73ef35a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6703994274139404, 'eval_accuracy': 0.624, 'eval_runtime': 28.8347, 'eval_samples_per_second': 34.68, 'eval_steps_per_second': 4.335, 'epoch': 0.61}\n",
      "{'loss': 0.6871, 'grad_norm': 1.9219670295715332, 'learning_rate': 2.9520000000000002e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3d717b169a498f88f312facc2913d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6594428420066833, 'eval_accuracy': 0.635, 'eval_runtime': 28.869, 'eval_samples_per_second': 34.639, 'eval_steps_per_second': 4.33, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6762, 'grad_norm': 9.921380996704102, 'learning_rate': 2.44e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88168b09862d442faa3330615e177a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6598255634307861, 'eval_accuracy': 0.61, 'eval_runtime': 28.7437, 'eval_samples_per_second': 34.79, 'eval_steps_per_second': 4.349, 'epoch': 1.02}\n",
      "{'loss': 0.659, 'grad_norm': 3.852686643600464, 'learning_rate': 1.9280000000000002e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375df435e53344d08432f29cce36548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6364945769309998, 'eval_accuracy': 0.652, 'eval_runtime': 28.7977, 'eval_samples_per_second': 34.725, 'eval_steps_per_second': 4.341, 'epoch': 1.23}\n",
      "{'loss': 0.6475, 'grad_norm': 3.364405870437622, 'learning_rate': 1.4160000000000002e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f487dc2c104eaa826cb30fb4dd413d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6269851326942444, 'eval_accuracy': 0.656, 'eval_runtime': 28.7887, 'eval_samples_per_second': 34.736, 'eval_steps_per_second': 4.342, 'epoch': 1.43}\n",
      "{'loss': 0.6478, 'grad_norm': 6.550530433654785, 'learning_rate': 9.04e-06, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e9eb18d40441f08ef3f8a2a1959f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.621903657913208, 'eval_accuracy': 0.653, 'eval_runtime': 28.6308, 'eval_samples_per_second': 34.927, 'eval_steps_per_second': 4.366, 'epoch': 1.64}\n",
      "{'loss': 0.6332, 'grad_norm': 9.44797420501709, 'learning_rate': 3.92e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7340a95fbde42c58461b600c08f2181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6183028817176819, 'eval_accuracy': 0.668, 'eval_runtime': 28.8974, 'eval_samples_per_second': 34.605, 'eval_steps_per_second': 4.326, 'epoch': 1.84}\n",
      "{'train_runtime': 1013.908, 'train_samples_per_second': 9.863, 'train_steps_per_second': 1.233, 'train_loss': 0.6692172241210937, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.6692172241210937, metrics={'train_runtime': 1013.908, 'train_samples_per_second': 9.863, 'train_steps_per_second': 1.233, 'total_flos': 2632290263040000.0, 'train_loss': 0.6692172241210937, 'epoch': 2.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7085989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.6797</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.6704</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>640</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>768</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>896</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1152</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.6183</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Step  Training Loss  Validation Loss  Accuracy\n",
       "0   128         0.7068           0.6886     0.551\n",
       "1   256         0.6895           0.6797     0.595\n",
       "2   384         0.6873           0.6704     0.624\n",
       "3   512         0.6871           0.6594     0.635\n",
       "4   640         0.6762           0.6598     0.610\n",
       "5   768         0.6590           0.6365     0.652\n",
       "6   896         0.6475           0.6270     0.656\n",
       "7  1024         0.6478           0.6219     0.653\n",
       "8  1152         0.6332           0.6183     0.668"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = trainer.state.log_history\n",
    "\n",
    "train_loss_by_step = {}\n",
    "eval_by_step = {}\n",
    "\n",
    "for log in logs:\n",
    "    if \"loss\" in log and \"eval_loss\" not in log:\n",
    "        train_loss_by_step[log[\"step\"]] = log[\"loss\"]\n",
    "    if \"eval_loss\" in log:\n",
    "        eval_by_step[log[\"step\"]] = {\n",
    "            \"Validation Loss\": log[\"eval_loss\"],\n",
    "            \"Accuracy\": log.get(\"eval_accuracy\")\n",
    "        }\n",
    "\n",
    "rows = []\n",
    "for step in sorted(eval_by_step.keys()):\n",
    "    rows.append({\n",
    "        \"Step\": step,\n",
    "        \"Training Loss\": round(train_loss_by_step.get(step, float(\"nan\")), 4),\n",
    "        \"Validation Loss\": round(eval_by_step[step][\"Validation Loss\"], 4),\n",
    "        \"Accuracy\": round(eval_by_step[step][\"Accuracy\"], 4),\n",
    "    })\n",
    "\n",
    "df_peft_results = pd.DataFrame(rows)\n",
    "df_peft_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111faf3a-272b-4dea-9f9a-8b00e7e194a5",
   "metadata": {},
   "source": [
    "## Compare the results of the different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b8a0811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Final Training Loss</th>\n",
       "      <th>Final Validation Loss</th>\n",
       "      <th>Final Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Custom LoRA</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEFT LoRA</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.6183</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Approach  Final Training Loss  Final Validation Loss  Final Accuracy\n",
       "0  Custom LoRA               0.6750                 0.6575           0.633\n",
       "1    PEFT LoRA               0.6332                 0.6183           0.668"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Approach\": [\"Custom LoRA\", \"PEFT LoRA\"],\n",
    "    \"Final Training Loss\": [\n",
    "        df_results[\"Training Loss\"].dropna().iloc[-1],\n",
    "        df_peft_results[\"Training Loss\"].iloc[-1]\n",
    "    ],\n",
    "    \"Final Validation Loss\": [\n",
    "        df_results[\"Validation Loss\"].iloc[-1],\n",
    "        df_peft_results[\"Validation Loss\"].iloc[-1]\n",
    "    ],\n",
    "    \"Final Accuracy\": [\n",
    "        df_results[\"Accuracy\"].iloc[-1],\n",
    "        df_peft_results[\"Accuracy\"].iloc[-1]\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7933b06b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
